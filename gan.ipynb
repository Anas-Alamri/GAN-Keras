{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPlnYCg4HfMDNVXyrfmq9J/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pravinkr/GAN-Keras/blob/master/gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TguanjKxu-DE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.layers import Conv2D,  Dropout, Flatten, Dense, Input, Reshape, UpSampling2D, BatchNormalization\n",
        "from keras.layers import Activation, Conv2DTranspose\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.datasets import mnist, fashion_mnist\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "class GAN:\n",
        "\n",
        "\tdef __init__(self, rows=28, cols=28, channels=1):\n",
        "\t\tself.rows = rows\n",
        "\t\tself.cols = cols\n",
        "\t\tself.channels = channels\n",
        "\t\tself.shape = (self.rows, self.cols, self.channels)\n",
        "\t\tself.latent_size = 100\n",
        "\t\tself.sample_rows = 5\n",
        "\t\tself.sample_cols = 5\n",
        "\t\tself.sample_path = 'images'\n",
        "\n",
        "\t\toptimizer = RMSprop(lr=0.0008, clipvalue=1.0, decay=6e-8)\n",
        "\t\t\n",
        "\t\t\n",
        "\t\timage_shape = self.shape\n",
        "\t\tseed_size = self.latent_size\n",
        "\t\t\n",
        "\t\t#Get the discriminator and generator Models\n",
        "\t\tprint(\"Build Discriminator\")\n",
        "\t\tself.discriminator = self.build_discriminator()\n",
        "\t\t\n",
        "\t\tself.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  \n",
        "\t\tprint(\"Build Generator\")\n",
        "\t\t\n",
        "\t\tself.generator = self.build_generator(seed_size)\n",
        "\t\t\n",
        "\t\trandom_input = Input(shape=(seed_size,))\n",
        "\t\tgenerated_image = self.generator(random_input)\n",
        "\t\t\n",
        "\t\tself.discriminator.trainable = False\n",
        "\t\tvalidity = self.discriminator(generated_image)\n",
        "\t\t\n",
        "\t\tself.combined_model = Model(random_input, validity)\n",
        "\t\tself.combined_model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
        "\t\t\n",
        "\tdef build_discriminator1(self):\n",
        "\t\n",
        "\t\tinput_shape = self.shape\n",
        "\t\tmodel = Sequential()\n",
        "\t\tmodel.add(Conv2D(64, (3,3), strides=2, padding='same', input_shape=input_shape))\n",
        "\t\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t\tmodel.add(Dropout(0.4))\n",
        "\t\t\n",
        "\t\tmodel.add(Conv2D(128,(3,3), strides=2, padding='same'))\n",
        "\t\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t\tmodel.add(Dropout(0.4))\n",
        "\t\t\n",
        "\t\tmodel.add(Conv2D(256, (3,3), strides=2, padding='same'))\n",
        "\t\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t\tmodel.add(Dropout(0.4))\n",
        "\t\t\n",
        "\t\tmodel.add(Conv2D(512, (3,3), padding='same'))\n",
        "\t\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t\tmodel.add(Dropout(0.4))\n",
        "\t\t\n",
        "\t\tmodel.add(Flatten())\n",
        "\t\t\n",
        "\t\tmodel.add(Dense(1,activation='sigmoid'))\n",
        "\t\t\n",
        "\t\t#output = model\n",
        "\t\t#inp = Input(shape=input_shape) \n",
        "\t\t\n",
        "\t\t\n",
        "\t\t#model.summary()\n",
        "\t\t\n",
        "\t\tinput_image = Input(shape=input_shape)\n",
        "\t\t\n",
        "\t\tvalidity = model(input_image)\n",
        "\t\t\n",
        "\t\treturn Model(input_image,validity)\t\n",
        "\n",
        "\tdef build_discriminator(self):\n",
        "\t\n",
        "\t\tdef conv_block(x,filter_size,strides=2, padding='same' ):\n",
        "\t\t\tx = Conv2D(filter_size, (3,3), strides = strides, padding = padding)(x)\n",
        "\t\t\tx = LeakyReLU(alpha=0.2)(x)\n",
        "\t\t\tx = Dropout(0.3)(x)\n",
        "\t\t\treturn x\n",
        "\t\t\n",
        "\t\tinput_shape = (self.rows, self.cols, self.channels)\n",
        "\t\t\n",
        "\t\tinput_image = Input(shape=input_shape)\n",
        "\t\t\n",
        "\t\tx = conv_block(input_image, 64, strides=(2,2))\n",
        "\t\tx = conv_block(x, 128, strides=(1,1))\n",
        "\t\tx = conv_block(x,256, strides=(2,2))\n",
        "\t\tx = conv_block(x,512, (1,1))\n",
        "\t\t\n",
        "\t\tfeatures = Flatten()(x)\n",
        "\t\treal_or_fake = Dense(1, activation='sigmoid')(features)\n",
        "\t\t\n",
        "\t\t\n",
        "\t\treturn Model(input_image,real_or_fake)\n",
        "\n",
        "\tdef build_generator(self, latent_size):\n",
        "\t\n",
        "\t\n",
        "\t\tseed_size = latent_size\n",
        "\t\tmodel = Sequential()\n",
        "\t\tmodel.add(Dense(7*7*256, input_dim=seed_size))\n",
        "\t\tmodel.add(BatchNormalization(momentum=0.9))\n",
        "\t\tmodel.add(Activation('relu'))\n",
        "\t\t\n",
        "\t\tmodel.add(Reshape((7,7,256)))\n",
        "\t\tmodel.add(Dropout(0.4))\n",
        "\t\t\n",
        "\t\tmodel.add(Conv2DTranspose(128,(5,5),padding='same'))\n",
        "\t\tmodel.add(BatchNormalization(momentum=0.9))\n",
        "\t\tmodel.add(Activation('relu'))\n",
        "\t\tmodel.add(UpSampling2D())\n",
        "\t\t\n",
        "\t\tmodel.add(Conv2DTranspose(64,(3,3),padding='same'))\n",
        "\t\tmodel.add(BatchNormalization(momentum=0.9))\n",
        "\t\tmodel.add(Activation('relu'))\n",
        "\t\tmodel.add(UpSampling2D())\n",
        "\t\t\n",
        "\t\tmodel.add(Conv2DTranspose(32,(3,3),padding='same'))\n",
        "\t\tmodel.add(BatchNormalization(momentum=0.9))\n",
        "\t\tmodel.add(Activation('relu'))\n",
        "\t\t\n",
        "\t\tmodel.add(Conv2DTranspose(1,(3,3),padding='same'))\n",
        "\t\tmodel.add(Activation('sigmoid'))\n",
        "\t\t\n",
        "\t\tinput = Input(shape=(seed_size,))\n",
        "\t\t\n",
        "\t\tgenerated_image = model(input)\n",
        "\t\t\n",
        "\t\t#model.summary()\n",
        "\t\t\n",
        "\t\treturn(Model(input,generated_image))\n",
        "\n",
        "\t\t\n",
        "\tdef build_generator1(self, latent_size):\n",
        "\t\n",
        "\t\tdef up_sampling_block(x, filter_size):\n",
        "\t\t\tx = UpSampling2D(size=(2,2))(x)\n",
        "\t\t\tx = Conv2D(filter_size, (5,5), padding='same',activation='relu')(x)\n",
        "\t\t\treturn x\n",
        "\t\t\n",
        "\t\tlatent_input = Input(shape=(latent_size,))\n",
        "\t\t\n",
        "\t\tx = Dense(1024, activation='relu')(latent_input)\n",
        "\t\tx = Dense(7*7*512,activation='relu')(x)\n",
        "\t\tx = Reshape((7,7,512))(x)\n",
        "\t\tx = Conv2D(256, (3,3), padding='same')(x)\n",
        "\t\t\n",
        "\t\tx = up_sampling_block(x,128)\n",
        "\t\tx = up_sampling_block(x,64)\n",
        "\t\t#x = up_sampling_block(x,32)\n",
        "\t\tx = Conv2D(32, (3,3), padding='same')(x)\n",
        "\t\t\n",
        "\t\tgen_image = Conv2D(1, (3,3), padding='same')(x)\n",
        "\t\t\n",
        "\t\tmodel = Model(latent_input, gen_image)\n",
        "\t\t\n",
        "\t\treturn model\n",
        "\n",
        "\n",
        "\tdef plot_sample_images(self, epoch, noise):\n",
        "\t\tr, c = self.sample_rows, self.sample_cols\n",
        "\t\t#noise = np.random.normal(0, 1, (r * c, self.latent_size))\n",
        "\t\tgen_imgs = self.generator.predict(noise)\n",
        "\t\t#print(\"gen_imgs.shape\",gen_imgs.shape)\n",
        "\t\t\n",
        "\t\t# Rescale images 0 - 1\n",
        "\t\t#gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\t\t#gen_imgs = gen_imgs.reshape(gen_imgs.shape[0], self.rows, self.cols,1)\n",
        "\n",
        "\t\t\n",
        "\t\tfilename = os.path.join(self.sample_path,'%d.png'% epoch)\n",
        "\t\tfig, axs = plt.subplots(r, c)\n",
        "\t\tcnt = 0\n",
        "\t\tfor i in range(r):\n",
        "\t\t\tfor j in range(c):\n",
        "\t\t\t\taxs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "\t\t\t\taxs[i,j].axis('off')\n",
        "\t\t\t\tcnt += 1\n",
        "\t\t#fig.savefig(\"images/%d.png\" % epoch)\n",
        "\t\tfig.savefig(filename)\n",
        "\t\tplt.close()\n",
        "\n",
        "\n",
        "\tdef plot_loss(self,losses):\n",
        "\t\t\"\"\"\n",
        "\t\t@losses.keys():\n",
        "\t\t\t0: loss\n",
        "\t\t\t1: accuracy\n",
        "\t\t\"\"\"\n",
        "\t\td_loss = [v[0] for v in losses[\"D\"]]\n",
        "\t\tg_loss = [v[0] for v in losses[\"G\"]]\n",
        "\t\t\n",
        "\t\tplt.figure(figsize=(10,8))\n",
        "\t\tplt.plot(d_loss, label=\"Discriminator loss\")\n",
        "\t\tplt.plot(g_loss, label=\"Generator loss\")\n",
        "\t\t\n",
        "\t\tplt.xlabel('Epochs')\n",
        "\t\tplt.ylabel('Loss')\n",
        "\t\tplt.legend()\n",
        "\t\tplt.show()\n",
        "\n",
        "\t\t\n",
        "\tdef train(self, epochs=10000, batch_size=32, save_freq=200):\n",
        "   \n",
        "\t\tseed_size = self.latent_size\n",
        "\t\t\n",
        "    #Load Dataset\n",
        "\t\t#(x_train,_),(_,_) = mnist.load_data()\n",
        "\t\t(x_train,_),(_,_) = fashion_mnist.load_data()\n",
        "\t\t\n",
        "\t\t#normalize and reset train set in range (0,1) # normalizing to (-1,1) seems to be not working.\n",
        "\t\t\n",
        "\t\tx_train = np.expand_dims(x_train, axis=-1)\n",
        "\n",
        "\t\t#x_train = (x_train.astype('float32') / 127.5 ) - 1. # Normalizing this way doesn't work during training.\n",
        "\t\t\n",
        "\t\tx_train = x_train.astype('float32')/255.0 #Normalizing  this way does work during training.\n",
        "\t\t\n",
        "  \n",
        "\t\tprint(\"x_train.shape\",x_train.shape)\n",
        "\n",
        "    #Ground Truth. Setting real images labels to True\n",
        "\t\ty_real = np.ones((batch_size,1))\n",
        "\n",
        "    #Setting fake images labels to False\n",
        "\t\ty_fake = np.zeros((batch_size,1))\n",
        "\t\t\n",
        "    \n",
        "\t\t#fixed_seed = np.random.normal(0,1,size=[25,seed_size])\n",
        "\t\t\n",
        "\t\tcnt = 1\n",
        "\t\t\n",
        "\t\t#Generating Fixed noise to be passed for sampling with same inputs after set of epochs and seeing the results\n",
        "\t\tnoise_input = np.random.normal(0,1,size=[self.sample_rows*self.sample_cols,seed_size])\n",
        "\t\t\n",
        "\t\t#Setup loss vector to store losses for Generator and Discriminator\n",
        "\t\t\n",
        "\t\tlosses = {\"D\":[], \"G\":[]}\n",
        "\n",
        "\t\tpath = self.sample_path\n",
        "\t\tif not os.path.isdir(path):\n",
        "\t\t  os.mkdir(path)\n",
        "\n",
        "\t\tfor epoch in range(epochs):\n",
        "\n",
        "\n",
        "      #Training of Discriminator. Taking random samples of batch_size #\n",
        "\t\t\tnoise = np.random.normal(0,1,size=[batch_size,seed_size])\n",
        "\t\t\t\n",
        "      #take random batched of indexes for x_train\n",
        "\t\t\tidx = np.random.randint(0,x_train.shape[0],size=batch_size)\n",
        "\t\t\t\n",
        "\t\t\t#print(idx[0:10])\n",
        "\t\t\tx_real = x_train[idx]\n",
        "\t\t\t\n",
        "\t\t\t#print(\"x_real.shape\",x_real.shape)\n",
        "\t\t\t\n",
        "\t\t\t#Generate some fake images\n",
        "\t\t\tx_fake = self.generator.predict(noise)\n",
        "      \n",
        "\t\t\tx = np.concatenate((x_real,x_fake))\n",
        "\t\t\t\n",
        "\t\t\ty = np.ones([2*batch_size,1])\n",
        "\t\t\ty[batch_size:,:] = 0\n",
        "\t\t\t\n",
        "\t\t\t#Train discriminator on real and fake\n",
        "\t\t\td_loss = self.discriminator.train_on_batch(x,y)\n",
        "\t\t\t\n",
        "\t\t\t#Train Generator on Calculated loss\n",
        "\t\t\ty = np.ones([batch_size, 1])\n",
        "\n",
        "\t\t\t#noise = np.random.uniform(-1.0, 1.0, size=[batch_size, SEED_SIZE])\n",
        "\t\t\tnoise = np.random.normal(0,1,size=[batch_size,seed_size])\n",
        "\t\t\t\n",
        "\t\t\tg_loss = self.combined_model.train_on_batch(noise,y)\n",
        "\t\t\t\n",
        "\t\t\tlosses[\"D\"].append(d_loss)\n",
        "\t\t\tlosses[\"G\"].append(g_loss)\n",
        "\t\t\t\n",
        "\t\t\t#Time for an update\n",
        "\t\t\t\n",
        "\t\t\tif save_freq > 0:\n",
        "\t\t\t\tif epoch % save_freq == 0:\n",
        "\n",
        "\t\t\t\t\tprint (\"epoch %d: [D loss: %f, acc.: %.2f%%] [G loss: %f, acc.: %.2f%%]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss[0], 100*g_loss[1]))\n",
        "\n",
        "\t\t\t\t\tself.plot_sample_images(epoch, noise_input)\n",
        "\t\t\t\t\tcnt+=1\n",
        "\n",
        "\t\tself.plot_loss(losses)\n",
        "\t\t\n",
        "if __name__ == '__main__':\n",
        "\t\n",
        "\tgan = GAN()\n",
        "\t#gan.train(epochs=14000, batch_size=32, save_freq=200)\t\t\n",
        "\tgan.train(epochs=50000)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_Z3Tu6AiG8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}