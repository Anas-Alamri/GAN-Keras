{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cgan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMSgFb4USLbldL/+v7fbAfy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pravinkr/GAN-Keras/blob/master/cgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TguanjKxu-DE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.layers import Conv2D,  Dropout, Flatten, Dense, Input, Reshape\n",
        "from keras.layers import Activation, Conv2DTranspose, UpSampling2D, BatchNormalization, Embedding, multiply\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.datasets import mnist, fashion_mnist\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "class CGAN:\n",
        "\n",
        "\tdef __init__(self, rows=28, cols=28, channels=1):\n",
        "\t\tself.rows = rows\n",
        "\t\tself.cols = cols\n",
        "\t\tself.channels = channels\n",
        "\t\tself.shape = (self.rows, self.cols, self.channels)\n",
        "\t\tself.latent_size = 100\n",
        "\t\tself.sample_rows = 2\n",
        "\t\tself.sample_cols = 5\n",
        "\t\tself.sample_path = 'images'\n",
        "\t\tself.num_classes = 10\n",
        "\n",
        "\t\toptimizer = RMSprop(lr=0.0008, clipvalue=1.0, decay=6e-8)\n",
        "\t\t\n",
        "\t\t\n",
        "\t\timage_shape = self.shape\n",
        "\t\tseed_size = self.latent_size\n",
        "\t\t\n",
        "\t\t\n",
        "\t\t#Get the discriminator and generator Models\n",
        "\t\tprint(\"Build Discriminator\")\n",
        "\t\tself.discriminator = self.build_discriminator()\n",
        "\t\t\n",
        "\t\tself.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  \n",
        "\t\tprint(\"Build Generator\")\n",
        "\t\t\n",
        "\t\tself.generator = self.build_generator()\n",
        "\t\t\n",
        "\t\trandom_input = Input(shape=(seed_size,))\n",
        "\t\tlabel = Input(shape=(1,))\n",
        "\t\t\n",
        "\t\t#Pass noise/random_input and label as input to the generator\n",
        "\t\tgenerated_image = self.generator([random_input,label])\n",
        "\t\t\n",
        "\t\t#Put discriminator.trainable to False. We do not want to train the discriminator at this point in time\n",
        "\t\tself.discriminator.trainable = False\n",
        "\t\t\n",
        "\t\t#Pass generated image and label as input to the discriminator\n",
        "\t\tvalidity = self.discriminator([generated_image,label])\n",
        "\t\t\n",
        "\t\t#Pass radom input and label as input to the combined model\n",
        "\t\tself.combined_model = Model([random_input,label], validity)\n",
        "\t\tself.combined_model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
        "\t\t\n",
        "\tdef build_discriminator(self):\n",
        "\t\n",
        "\t\tinput_shape = self.shape\n",
        "\t\tmodel = Sequential()\n",
        "\t\tmodel.add(Conv2D(64, (3,3), strides=2, padding='same', input_shape=input_shape))\n",
        "\t\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t\tmodel.add(Dropout(0.4))\n",
        "\t\t\n",
        "\t\tmodel.add(Conv2D(128,(3,3), strides=2, padding='same'))\n",
        "\t\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t\tmodel.add(Dropout(0.4))\n",
        "\t\t\n",
        "\t\tmodel.add(Conv2D(256, (3,3), strides=2, padding='same'))\n",
        "\t\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t\tmodel.add(Dropout(0.4))\n",
        "\t\t\n",
        "\t\tmodel.add(Conv2D(512, (3,3), padding='same'))\n",
        "\t\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t\tmodel.add(Dropout(0.4))\n",
        "\t\t\n",
        "\t\tmodel.add(Flatten())\n",
        "\t\t\n",
        "\t\tmodel.add(Dense(1,activation='sigmoid'))\n",
        "\t\t\n",
        "\n",
        "\t\tinput_image = Input(shape=input_shape)\n",
        "\t\tlabel = Input(shape=(1,))\n",
        "\t\t\n",
        "\t\tlabel_embeddings = Flatten()(Embedding(self.num_classes, np.prod(self.shape))(label))\n",
        "\t\tflat_image = Flatten()(input_image)\n",
        "\t\t\n",
        "\t\t\n",
        "\t\tmodel_input = multiply([flat_image, label_embeddings])\n",
        "\t\tmodel_input = Reshape((28,28,1))(model_input)\n",
        "\t\n",
        "\t\t\n",
        "\t\tvalidity = model(model_input)\n",
        "\t\t\n",
        "\t\treturn Model([input_image,label],validity)\t\n",
        "\n",
        "\tdef build_generator(self):\n",
        "\t\n",
        "\t\n",
        "\t\tseed_size = self.latent_size\n",
        "\t\tmodel = Sequential()\n",
        "\t\tmodel.add(Dense(7*7*256, input_dim=seed_size))\n",
        "\t\tmodel.add(BatchNormalization(momentum=0.9))\n",
        "\t\tmodel.add(Activation('relu'))\n",
        "\t\t\n",
        "\t\tmodel.add(Reshape((7,7,256)))\n",
        "\t\tmodel.add(Dropout(0.4))\n",
        "\t\t\n",
        "\t\tmodel.add(Conv2DTranspose(128,(5,5),padding='same'))\n",
        "\t\tmodel.add(BatchNormalization(momentum=0.9))\n",
        "\t\tmodel.add(Activation('relu'))\n",
        "\t\tmodel.add(UpSampling2D())\n",
        "\t\t\n",
        "\t\tmodel.add(Conv2DTranspose(64,(3,3),padding='same'))\n",
        "\t\tmodel.add(BatchNormalization(momentum=0.9))\n",
        "\t\tmodel.add(Activation('relu'))\n",
        "\t\tmodel.add(UpSampling2D())\n",
        "\t\t\n",
        "\t\tmodel.add(Conv2DTranspose(32,(3,3),padding='same'))\n",
        "\t\tmodel.add(BatchNormalization(momentum=0.9))\n",
        "\t\tmodel.add(Activation('relu'))\n",
        "\t\t\n",
        "\t\tmodel.add(Conv2DTranspose(1,(3,3),padding='same'))\n",
        "\t\tmodel.add(Activation('sigmoid'))\n",
        "\t\t\n",
        "\t\tnoise = Input(shape=(seed_size,))\n",
        "\t\tlabel = Input(shape = (1,), dtype='int32')\n",
        "\t\t\n",
        "\t\tlabel_embeddings = Flatten()(Embedding(self.num_classes,self.latent_size)(label))\n",
        "\t\t\n",
        "\t\t\n",
        "\t\tinput = multiply([noise,label_embeddings])\n",
        "\t\t\n",
        "\t\tgenerated_image = model(input)\n",
        "\t\t\n",
        "\t\n",
        "\t\treturn(Model([noise,label],generated_image))\n",
        "\n",
        "\t\t\n",
        "\n",
        "\tdef plot_sample_images(self, epoch, noise):\n",
        "\t\tr, c = self.sample_rows, self.sample_cols\n",
        "\t\t\n",
        "\t\tsampled_labels = np.arange(0, self.num_classes).reshape(-1, 1)\n",
        "\t\n",
        "\t\tgen_imgs = self.generator.predict([noise,sampled_labels])\n",
        "\t\t\n",
        "\t\tfilename = os.path.join(self.sample_path,'%d.png'% epoch)\n",
        "\t\tfig, axs = plt.subplots(r, c)\n",
        "\t\tcnt = 0\n",
        "\t\tfor i in range(r):\n",
        "\t\t\tfor j in range(c):\n",
        "\t\t\t\taxs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "\t\t\t\taxs[i,j].axis('off')\n",
        "\t\t\t\tcnt += 1\n",
        "\t\tfig.savefig(filename)\n",
        "\t\tplt.close()\n",
        "\n",
        "\n",
        "\tdef plot_loss(self,losses):\n",
        "\t\t\"\"\"\n",
        "\t\t@losses.keys():\n",
        "\t\t\t0: loss\n",
        "\t\t\t1: accuracy\n",
        "\t\t\"\"\"\n",
        "\t\td_loss = [v[0] for v in losses[\"D\"]]\n",
        "\t\tg_loss = [v[0] for v in losses[\"G\"]]\n",
        "\t\t\n",
        "\t\tplt.figure(figsize=(10,8))\n",
        "\t\tplt.plot(d_loss, label=\"Discriminator loss\")\n",
        "\t\tplt.plot(g_loss, label=\"Generator loss\")\n",
        "\t\t\n",
        "\t\tplt.xlabel('Epochs')\n",
        "\t\tplt.ylabel('Loss')\n",
        "\t\tplt.legend()\n",
        "\t\tplt.show()\n",
        "\n",
        "\t\t\n",
        "\tdef train(self, epochs=10000, batch_size=32, save_freq=200):\n",
        "   \n",
        "\t\tseed_size = self.latent_size\n",
        "\t\t\n",
        "    #Load Dataset\n",
        "\t\t#(x_train,y_train),(_,_) = mnist.load_data()\n",
        "\t\t(x_train,y_train),(_,_) = fashion_mnist.load_data()\n",
        "\t\t\n",
        "\t\t#normalize and reset train set in range (0,1) # normalizing to (-1,1) seems to be not working.\n",
        "\t\t\n",
        "\t\tx_train = np.expand_dims(x_train, axis=-1)\n",
        "\t\ty_train = y_train.reshape(-1,1)\n",
        "\n",
        "\t\t#x_train = (x_train.astype('float32') / 127.5 ) - 1. # Normalizing this way doesn't work during training.\n",
        "\t\t\n",
        "\t\tx_train = x_train.astype('float32')/255.0 #Normalizing  this way does work during training.\n",
        "\t\t\n",
        "  \n",
        "\t\tprint(\"x_train.shape\",x_train.shape)\n",
        "\n",
        "\t\t#Ground Truth. Setting real images labels to True\n",
        "\t\ty_real = np.ones((batch_size,1))\n",
        "\n",
        "\t\t#Setting fake images labels to False\n",
        "\t\ty_fake = np.zeros((batch_size,1))\n",
        "\t\t\n",
        "    \n",
        "\t\t#fixed_seed = np.random.normal(0,1,size=[25,seed_size])\n",
        "\t\t\n",
        "\t\tcnt = 1\n",
        "\t\t\n",
        "\t\t#Generating Fixed noise to be passed for sampling with same inputs after set of epochs and seeing the results\n",
        "\t\tnoise_input = np.random.normal(0,1,size=[self.sample_rows*self.sample_cols,seed_size])\n",
        "\t\t\n",
        "\t\t#Setup loss vector to store losses for Generator and Discriminator\n",
        "\t\t\n",
        "\t\tlosses = {\"D\":[], \"G\":[]}\n",
        "\n",
        "\t\tpath = self.sample_path\n",
        "\t\tif not os.path.isdir(path):\n",
        "\t\t  os.mkdir(path)\n",
        "\n",
        "\t\tfor epoch in range(epochs):\n",
        "\n",
        "\n",
        "      #Training of Discriminator. Taking random samples of batch_size #\n",
        "\t\t\tnoise = np.random.normal(0,1,size=[batch_size,seed_size])\n",
        "\t\t\t\n",
        "      #take random batched of indexes for x_train\n",
        "\t\t\tidx = np.random.randint(0,x_train.shape[0],size=batch_size)\n",
        "\t\t\t\n",
        "\t\t\tx_real, y_real = x_train[idx], y_train[idx]\n",
        "\t\t\t\n",
        "\t\t\t\n",
        "\t\t\t#Generate some fake images\n",
        "\t\t\t#print(\"generator.predit\")\n",
        "\t\t\tx_fake = self.generator.predict([noise,y_real])\n",
        "\t\t\t#print(\"generator.predit done\")\n",
        "\n",
        "\t\t\tx = np.concatenate((x_real,x_fake))\n",
        "\t\t\tconcat_labels = np.concatenate((y_real, y_real))\n",
        "\t\t\t\n",
        "\t\t\ty = np.ones([2*batch_size,1])\n",
        "\t\t\ty[batch_size:,:] = 0\n",
        "\t\t\t\n",
        "\t\t\t#Train discriminator on real and fake\n",
        "\t\t\td_loss = self.discriminator.train_on_batch([x,concat_labels],y)\n",
        "\t \n",
        "\t\t\t#Train Generator on Calculated loss\n",
        "\t\t\ty = np.ones([batch_size, 1])\n",
        "\n",
        "\t\t\t#noise = np.random.uniform(-1.0, 1.0, size=[batch_size, SEED_SIZE])\n",
        "\t\t\tnoise = np.random.normal(0,1,size=[batch_size,seed_size])\n",
        "\t\t\tsampled_labels = np.random.randint(0, self.num_classes, batch_size).reshape(-1, 1)\n",
        "\t\t\t\n",
        "\t\t\tg_loss = self.combined_model.train_on_batch([noise,sampled_labels],y)\n",
        "\t\t\t\n",
        "\t\t\tlosses[\"D\"].append(d_loss)\n",
        "\t\t\tlosses[\"G\"].append(g_loss)\n",
        "\t\t\t\n",
        "\t\t\t#Time for an update\n",
        "\t\t\t\n",
        "\t\t\tif save_freq > 0:\n",
        "\t\t\t\tif epoch % save_freq == 0:\n",
        "\t\t\t\n",
        "\t\t\t\t\tprint (\"epoch %d: [D loss: %f, acc.: %.2f%%] [G loss: %f, acc.: %.2f%%]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss[0], 100*g_loss[1]))\n",
        "\t\t\t\t\tself.plot_sample_images(epoch, noise_input)\n",
        "\t\t\t\t\tcnt+=1\n",
        "\n",
        "\t\tself.plot_loss(losses)\n",
        "\t\t\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSe8f9Ycvqrp",
        "colab_type": "code",
        "outputId": "166c1eac-34d9-4986-9a58-7d99ec5c7c16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gan = CGAN()\n",
        "\n",
        "gan.train(epochs=50000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build Discriminator\n",
            "Build Generator\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 3us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n",
            "x_train.shape (60000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0: [D loss: 0.693119, acc.: 54.69%] [G loss: 0.696970, acc.: 6.25%]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 200: [D loss: 0.701584, acc.: 40.62%] [G loss: 0.701804, acc.: 46.88%]\n",
            "epoch 400: [D loss: 0.689616, acc.: 51.56%] [G loss: 0.706656, acc.: 46.88%]\n",
            "epoch 600: [D loss: 0.691072, acc.: 57.81%] [G loss: 0.679907, acc.: 75.00%]\n",
            "epoch 800: [D loss: 0.693551, acc.: 45.31%] [G loss: 0.684830, acc.: 62.50%]\n",
            "epoch 1000: [D loss: 0.689256, acc.: 51.56%] [G loss: 0.715214, acc.: 34.38%]\n",
            "epoch 1200: [D loss: 0.693612, acc.: 45.31%] [G loss: 0.701208, acc.: 46.88%]\n",
            "epoch 1400: [D loss: 0.682727, acc.: 62.50%] [G loss: 0.680737, acc.: 59.38%]\n",
            "epoch 1600: [D loss: 0.699615, acc.: 40.62%] [G loss: 0.715369, acc.: 37.50%]\n",
            "epoch 1800: [D loss: 0.695145, acc.: 53.12%] [G loss: 0.686956, acc.: 62.50%]\n",
            "epoch 2000: [D loss: 0.691648, acc.: 48.44%] [G loss: 0.702620, acc.: 50.00%]\n",
            "epoch 2200: [D loss: 0.705293, acc.: 51.56%] [G loss: 0.565976, acc.: 100.00%]\n",
            "epoch 2400: [D loss: 0.699836, acc.: 57.81%] [G loss: 0.617335, acc.: 96.88%]\n",
            "epoch 2600: [D loss: 0.638591, acc.: 65.62%] [G loss: 0.705289, acc.: 46.88%]\n",
            "epoch 2800: [D loss: 0.448409, acc.: 87.50%] [G loss: 0.270055, acc.: 90.62%]\n",
            "epoch 3000: [D loss: 0.247126, acc.: 93.75%] [G loss: 0.115234, acc.: 93.75%]\n",
            "epoch 3200: [D loss: 0.620350, acc.: 67.19%] [G loss: 0.154300, acc.: 96.88%]\n",
            "epoch 3400: [D loss: 0.581602, acc.: 70.31%] [G loss: 1.205485, acc.: 31.25%]\n",
            "epoch 3600: [D loss: 0.730332, acc.: 62.50%] [G loss: 1.324389, acc.: 0.00%]\n",
            "epoch 3800: [D loss: 0.733814, acc.: 37.50%] [G loss: 0.784498, acc.: 34.38%]\n",
            "epoch 4000: [D loss: 0.653621, acc.: 57.81%] [G loss: 0.888129, acc.: 21.88%]\n",
            "epoch 4200: [D loss: 0.680083, acc.: 59.38%] [G loss: 0.728028, acc.: 31.25%]\n",
            "epoch 4400: [D loss: 0.632046, acc.: 60.94%] [G loss: 0.737744, acc.: 46.88%]\n",
            "epoch 4600: [D loss: 0.728201, acc.: 45.31%] [G loss: 0.780656, acc.: 31.25%]\n",
            "epoch 4800: [D loss: 0.636499, acc.: 60.94%] [G loss: 0.669604, acc.: 56.25%]\n",
            "epoch 5000: [D loss: 0.682538, acc.: 60.94%] [G loss: 0.708338, acc.: 62.50%]\n",
            "epoch 5200: [D loss: 0.626851, acc.: 60.94%] [G loss: 0.891452, acc.: 34.38%]\n",
            "epoch 5400: [D loss: 0.697464, acc.: 50.00%] [G loss: 0.814453, acc.: 34.38%]\n",
            "epoch 5600: [D loss: 0.654839, acc.: 59.38%] [G loss: 0.525118, acc.: 78.12%]\n",
            "epoch 5800: [D loss: 0.631497, acc.: 60.94%] [G loss: 0.642480, acc.: 68.75%]\n",
            "epoch 6000: [D loss: 0.668247, acc.: 60.94%] [G loss: 0.809957, acc.: 34.38%]\n",
            "epoch 6200: [D loss: 0.633360, acc.: 65.62%] [G loss: 1.561879, acc.: 21.88%]\n",
            "epoch 6400: [D loss: 0.671525, acc.: 51.56%] [G loss: 0.764183, acc.: 28.12%]\n",
            "epoch 6600: [D loss: 0.649357, acc.: 56.25%] [G loss: 0.692618, acc.: 53.12%]\n",
            "epoch 6800: [D loss: 0.710870, acc.: 56.25%] [G loss: 0.684162, acc.: 46.88%]\n",
            "epoch 7000: [D loss: 0.621383, acc.: 64.06%] [G loss: 0.669803, acc.: 68.75%]\n",
            "epoch 7200: [D loss: 0.752454, acc.: 42.19%] [G loss: 0.724842, acc.: 40.62%]\n",
            "epoch 7400: [D loss: 0.680179, acc.: 59.38%] [G loss: 0.820913, acc.: 28.12%]\n",
            "epoch 7600: [D loss: 0.679378, acc.: 57.81%] [G loss: 0.897153, acc.: 21.88%]\n",
            "epoch 7800: [D loss: 0.694304, acc.: 59.38%] [G loss: 0.604658, acc.: 75.00%]\n",
            "epoch 8000: [D loss: 0.724554, acc.: 45.31%] [G loss: 0.656165, acc.: 59.38%]\n",
            "epoch 8200: [D loss: 0.624985, acc.: 62.50%] [G loss: 0.788753, acc.: 31.25%]\n",
            "epoch 8400: [D loss: 0.639930, acc.: 65.62%] [G loss: 0.805962, acc.: 40.62%]\n",
            "epoch 8600: [D loss: 0.675885, acc.: 48.44%] [G loss: 0.723732, acc.: 43.75%]\n",
            "epoch 8800: [D loss: 0.614549, acc.: 65.62%] [G loss: 0.772025, acc.: 40.62%]\n",
            "epoch 9000: [D loss: 0.695492, acc.: 54.69%] [G loss: 0.760485, acc.: 28.12%]\n",
            "epoch 9200: [D loss: 0.674916, acc.: 60.94%] [G loss: 0.714048, acc.: 53.12%]\n",
            "epoch 9400: [D loss: 0.618819, acc.: 60.94%] [G loss: 1.364667, acc.: 3.12%]\n",
            "epoch 9600: [D loss: 0.652014, acc.: 57.81%] [G loss: 0.842746, acc.: 50.00%]\n",
            "epoch 9800: [D loss: 0.675144, acc.: 62.50%] [G loss: 0.775844, acc.: 31.25%]\n",
            "epoch 10000: [D loss: 0.678009, acc.: 51.56%] [G loss: 0.637740, acc.: 62.50%]\n",
            "epoch 10200: [D loss: 0.675187, acc.: 46.88%] [G loss: 0.632039, acc.: 62.50%]\n",
            "epoch 10400: [D loss: 0.686168, acc.: 56.25%] [G loss: 0.545823, acc.: 84.38%]\n",
            "epoch 10600: [D loss: 0.671489, acc.: 57.81%] [G loss: 0.636557, acc.: 75.00%]\n",
            "epoch 10800: [D loss: 0.678056, acc.: 50.00%] [G loss: 0.707384, acc.: 46.88%]\n",
            "epoch 11000: [D loss: 0.705572, acc.: 59.38%] [G loss: 0.512010, acc.: 84.38%]\n",
            "epoch 11200: [D loss: 0.716637, acc.: 42.19%] [G loss: 0.786376, acc.: 25.00%]\n",
            "epoch 11400: [D loss: 0.606766, acc.: 62.50%] [G loss: 0.935016, acc.: 15.62%]\n",
            "epoch 11600: [D loss: 0.731656, acc.: 56.25%] [G loss: 0.796231, acc.: 43.75%]\n",
            "epoch 11800: [D loss: 0.680151, acc.: 57.81%] [G loss: 0.709887, acc.: 50.00%]\n",
            "epoch 12000: [D loss: 0.698979, acc.: 56.25%] [G loss: 0.660383, acc.: 62.50%]\n",
            "epoch 12200: [D loss: 0.665464, acc.: 56.25%] [G loss: 0.775856, acc.: 37.50%]\n",
            "epoch 12400: [D loss: 0.736096, acc.: 46.88%] [G loss: 0.790949, acc.: 21.88%]\n",
            "epoch 12600: [D loss: 0.695192, acc.: 53.12%] [G loss: 0.729607, acc.: 46.88%]\n",
            "epoch 12800: [D loss: 0.701156, acc.: 46.88%] [G loss: 0.695780, acc.: 59.38%]\n",
            "epoch 13000: [D loss: 0.663055, acc.: 60.94%] [G loss: 0.732767, acc.: 37.50%]\n",
            "epoch 13200: [D loss: 0.696460, acc.: 50.00%] [G loss: 0.752052, acc.: 40.62%]\n",
            "epoch 13400: [D loss: 0.682746, acc.: 59.38%] [G loss: 0.778066, acc.: 34.38%]\n",
            "epoch 13600: [D loss: 0.680815, acc.: 59.38%] [G loss: 0.772118, acc.: 28.12%]\n",
            "epoch 13800: [D loss: 0.704732, acc.: 53.12%] [G loss: 0.719845, acc.: 31.25%]\n",
            "epoch 14000: [D loss: 0.704042, acc.: 54.69%] [G loss: 0.753605, acc.: 31.25%]\n",
            "epoch 14200: [D loss: 0.688042, acc.: 56.25%] [G loss: 0.747505, acc.: 40.62%]\n",
            "epoch 14400: [D loss: 0.734641, acc.: 53.12%] [G loss: 0.657091, acc.: 59.38%]\n",
            "epoch 14600: [D loss: 0.719771, acc.: 39.06%] [G loss: 0.785611, acc.: 28.12%]\n",
            "epoch 14800: [D loss: 0.700563, acc.: 50.00%] [G loss: 0.728127, acc.: 43.75%]\n",
            "epoch 15000: [D loss: 0.713317, acc.: 43.75%] [G loss: 0.760704, acc.: 34.38%]\n",
            "epoch 15200: [D loss: 0.703272, acc.: 54.69%] [G loss: 0.737499, acc.: 40.62%]\n",
            "epoch 15400: [D loss: 0.710539, acc.: 45.31%] [G loss: 0.686512, acc.: 59.38%]\n",
            "epoch 15600: [D loss: 0.716694, acc.: 51.56%] [G loss: 0.836297, acc.: 18.75%]\n",
            "epoch 15800: [D loss: 0.690109, acc.: 46.88%] [G loss: 0.764848, acc.: 28.12%]\n",
            "epoch 16000: [D loss: 0.690759, acc.: 57.81%] [G loss: 0.706997, acc.: 46.88%]\n",
            "epoch 16200: [D loss: 0.655878, acc.: 59.38%] [G loss: 0.755973, acc.: 37.50%]\n",
            "epoch 16400: [D loss: 0.687252, acc.: 60.94%] [G loss: 0.742931, acc.: 43.75%]\n",
            "epoch 16600: [D loss: 0.694728, acc.: 51.56%] [G loss: 0.700235, acc.: 56.25%]\n",
            "epoch 16800: [D loss: 0.665848, acc.: 53.12%] [G loss: 0.674434, acc.: 78.12%]\n",
            "epoch 17000: [D loss: 0.698740, acc.: 45.31%] [G loss: 0.708399, acc.: 50.00%]\n",
            "epoch 17200: [D loss: 0.704708, acc.: 50.00%] [G loss: 0.715068, acc.: 37.50%]\n",
            "epoch 17400: [D loss: 0.717238, acc.: 46.88%] [G loss: 0.747755, acc.: 43.75%]\n",
            "epoch 17600: [D loss: 0.681026, acc.: 53.12%] [G loss: 0.713550, acc.: 46.88%]\n",
            "epoch 17800: [D loss: 0.679683, acc.: 51.56%] [G loss: 0.713227, acc.: 40.62%]\n",
            "epoch 18000: [D loss: 0.686253, acc.: 53.12%] [G loss: 0.698346, acc.: 53.12%]\n",
            "epoch 18200: [D loss: 0.716625, acc.: 40.62%] [G loss: 0.719810, acc.: 37.50%]\n",
            "epoch 18400: [D loss: 0.654087, acc.: 64.06%] [G loss: 0.726747, acc.: 43.75%]\n",
            "epoch 18600: [D loss: 0.664777, acc.: 62.50%] [G loss: 0.878704, acc.: 25.00%]\n",
            "epoch 18800: [D loss: 0.717685, acc.: 40.62%] [G loss: 0.743120, acc.: 43.75%]\n",
            "epoch 19000: [D loss: 0.698439, acc.: 53.12%] [G loss: 0.679421, acc.: 75.00%]\n",
            "epoch 19200: [D loss: 0.684966, acc.: 56.25%] [G loss: 0.820477, acc.: 28.12%]\n",
            "epoch 19400: [D loss: 0.675547, acc.: 56.25%] [G loss: 0.726009, acc.: 46.88%]\n",
            "epoch 19600: [D loss: 0.683339, acc.: 50.00%] [G loss: 0.680409, acc.: 62.50%]\n",
            "epoch 19800: [D loss: 0.678525, acc.: 56.25%] [G loss: 0.712798, acc.: 34.38%]\n",
            "epoch 20000: [D loss: 0.673105, acc.: 65.62%] [G loss: 0.739193, acc.: 37.50%]\n",
            "epoch 20200: [D loss: 0.680704, acc.: 48.44%] [G loss: 0.785248, acc.: 34.38%]\n",
            "epoch 20400: [D loss: 0.683845, acc.: 48.44%] [G loss: 0.720893, acc.: 46.88%]\n",
            "epoch 20600: [D loss: 0.639174, acc.: 62.50%] [G loss: 0.704989, acc.: 59.38%]\n",
            "epoch 20800: [D loss: 0.727502, acc.: 51.56%] [G loss: 0.816373, acc.: 6.25%]\n",
            "epoch 21000: [D loss: 0.699265, acc.: 50.00%] [G loss: 0.671260, acc.: 71.88%]\n",
            "epoch 21200: [D loss: 0.684807, acc.: 54.69%] [G loss: 0.716281, acc.: 46.88%]\n",
            "epoch 21400: [D loss: 0.673792, acc.: 56.25%] [G loss: 0.727965, acc.: 50.00%]\n",
            "epoch 21600: [D loss: 0.691831, acc.: 54.69%] [G loss: 0.683008, acc.: 46.88%]\n",
            "epoch 21800: [D loss: 0.691847, acc.: 46.88%] [G loss: 0.696913, acc.: 43.75%]\n",
            "epoch 22000: [D loss: 0.697965, acc.: 45.31%] [G loss: 0.698447, acc.: 53.12%]\n",
            "epoch 22200: [D loss: 0.670651, acc.: 64.06%] [G loss: 0.760420, acc.: 21.88%]\n",
            "epoch 22400: [D loss: 0.711023, acc.: 43.75%] [G loss: 0.683681, acc.: 56.25%]\n",
            "epoch 22600: [D loss: 0.690190, acc.: 53.12%] [G loss: 0.622997, acc.: 78.12%]\n",
            "epoch 22800: [D loss: 0.704492, acc.: 53.12%] [G loss: 0.812065, acc.: 18.75%]\n",
            "epoch 23000: [D loss: 0.685238, acc.: 59.38%] [G loss: 0.670865, acc.: 68.75%]\n",
            "epoch 23200: [D loss: 0.701035, acc.: 45.31%] [G loss: 0.627861, acc.: 78.12%]\n",
            "epoch 23400: [D loss: 0.683134, acc.: 60.94%] [G loss: 0.714813, acc.: 53.12%]\n",
            "epoch 23600: [D loss: 0.683368, acc.: 48.44%] [G loss: 0.728238, acc.: 34.38%]\n",
            "epoch 23800: [D loss: 0.694354, acc.: 57.81%] [G loss: 0.701319, acc.: 43.75%]\n",
            "epoch 24000: [D loss: 0.695651, acc.: 53.12%] [G loss: 0.707186, acc.: 53.12%]\n",
            "epoch 24200: [D loss: 0.700195, acc.: 53.12%] [G loss: 0.695545, acc.: 40.62%]\n",
            "epoch 24400: [D loss: 0.693134, acc.: 53.12%] [G loss: 0.655695, acc.: 59.38%]\n",
            "epoch 24600: [D loss: 0.708172, acc.: 46.88%] [G loss: 0.714420, acc.: 34.38%]\n",
            "epoch 24800: [D loss: 0.667809, acc.: 59.38%] [G loss: 0.652878, acc.: 68.75%]\n",
            "epoch 25000: [D loss: 0.700588, acc.: 48.44%] [G loss: 0.697363, acc.: 46.88%]\n",
            "epoch 25200: [D loss: 0.693885, acc.: 53.12%] [G loss: 0.736777, acc.: 34.38%]\n",
            "epoch 25400: [D loss: 0.720637, acc.: 43.75%] [G loss: 0.707750, acc.: 43.75%]\n",
            "epoch 25600: [D loss: 0.692296, acc.: 50.00%] [G loss: 0.671390, acc.: 56.25%]\n",
            "epoch 25800: [D loss: 0.707733, acc.: 46.88%] [G loss: 0.664095, acc.: 46.88%]\n",
            "epoch 26000: [D loss: 0.686160, acc.: 56.25%] [G loss: 0.669383, acc.: 53.12%]\n",
            "epoch 26200: [D loss: 0.697834, acc.: 48.44%] [G loss: 0.705867, acc.: 53.12%]\n",
            "epoch 26400: [D loss: 0.674106, acc.: 59.38%] [G loss: 0.771844, acc.: 37.50%]\n",
            "epoch 26600: [D loss: 0.731278, acc.: 42.19%] [G loss: 0.639529, acc.: 71.88%]\n",
            "epoch 26800: [D loss: 0.671665, acc.: 60.94%] [G loss: 0.681224, acc.: 56.25%]\n",
            "epoch 27000: [D loss: 0.686041, acc.: 57.81%] [G loss: 0.659070, acc.: 65.62%]\n",
            "epoch 27200: [D loss: 0.691490, acc.: 59.38%] [G loss: 0.717433, acc.: 37.50%]\n",
            "epoch 27400: [D loss: 0.723984, acc.: 48.44%] [G loss: 0.659855, acc.: 68.75%]\n",
            "epoch 27600: [D loss: 0.706201, acc.: 53.12%] [G loss: 0.686942, acc.: 59.38%]\n",
            "epoch 27800: [D loss: 0.723802, acc.: 45.31%] [G loss: 0.624311, acc.: 68.75%]\n",
            "epoch 28000: [D loss: 0.681738, acc.: 53.12%] [G loss: 0.748837, acc.: 40.62%]\n",
            "epoch 28200: [D loss: 0.696259, acc.: 40.62%] [G loss: 0.767790, acc.: 37.50%]\n",
            "epoch 28400: [D loss: 0.703677, acc.: 45.31%] [G loss: 0.714954, acc.: 53.12%]\n",
            "epoch 28600: [D loss: 0.689897, acc.: 50.00%] [G loss: 0.734422, acc.: 43.75%]\n",
            "epoch 28800: [D loss: 0.691467, acc.: 54.69%] [G loss: 0.718943, acc.: 46.88%]\n",
            "epoch 29000: [D loss: 0.719877, acc.: 45.31%] [G loss: 0.692663, acc.: 56.25%]\n",
            "epoch 29200: [D loss: 0.718896, acc.: 46.88%] [G loss: 0.695089, acc.: 46.88%]\n",
            "epoch 29400: [D loss: 0.684420, acc.: 65.62%] [G loss: 0.643738, acc.: 75.00%]\n",
            "epoch 29600: [D loss: 0.679794, acc.: 53.12%] [G loss: 0.591695, acc.: 84.38%]\n",
            "epoch 29800: [D loss: 0.699265, acc.: 54.69%] [G loss: 0.909406, acc.: 31.25%]\n",
            "epoch 30000: [D loss: 0.678951, acc.: 56.25%] [G loss: 0.712317, acc.: 56.25%]\n",
            "epoch 30200: [D loss: 0.714260, acc.: 42.19%] [G loss: 0.763094, acc.: 34.38%]\n",
            "epoch 30400: [D loss: 0.710172, acc.: 45.31%] [G loss: 0.740365, acc.: 34.38%]\n",
            "epoch 30600: [D loss: 0.674456, acc.: 60.94%] [G loss: 0.617365, acc.: 75.00%]\n",
            "epoch 30800: [D loss: 0.679475, acc.: 48.44%] [G loss: 0.737866, acc.: 34.38%]\n",
            "epoch 31000: [D loss: 0.692450, acc.: 50.00%] [G loss: 0.713157, acc.: 50.00%]\n",
            "epoch 31200: [D loss: 0.711182, acc.: 45.31%] [G loss: 0.749095, acc.: 34.38%]\n",
            "epoch 31400: [D loss: 0.676901, acc.: 59.38%] [G loss: 0.654623, acc.: 59.38%]\n",
            "epoch 31600: [D loss: 0.709867, acc.: 46.88%] [G loss: 0.687507, acc.: 59.38%]\n",
            "epoch 31800: [D loss: 0.727395, acc.: 48.44%] [G loss: 0.780805, acc.: 18.75%]\n",
            "epoch 32000: [D loss: 0.693934, acc.: 48.44%] [G loss: 0.737216, acc.: 46.88%]\n",
            "epoch 32200: [D loss: 0.693864, acc.: 46.88%] [G loss: 0.738842, acc.: 34.38%]\n",
            "epoch 32400: [D loss: 0.702108, acc.: 46.88%] [G loss: 0.693984, acc.: 59.38%]\n",
            "epoch 32600: [D loss: 0.688210, acc.: 54.69%] [G loss: 0.707528, acc.: 56.25%]\n",
            "epoch 32800: [D loss: 0.674883, acc.: 57.81%] [G loss: 0.896563, acc.: 12.50%]\n",
            "epoch 33000: [D loss: 0.693968, acc.: 50.00%] [G loss: 0.733474, acc.: 34.38%]\n",
            "epoch 33200: [D loss: 0.697010, acc.: 59.38%] [G loss: 0.646506, acc.: 71.88%]\n",
            "epoch 33400: [D loss: 0.699830, acc.: 54.69%] [G loss: 0.769710, acc.: 31.25%]\n",
            "epoch 33600: [D loss: 0.687655, acc.: 53.12%] [G loss: 0.663338, acc.: 59.38%]\n",
            "epoch 33800: [D loss: 0.705878, acc.: 50.00%] [G loss: 0.773355, acc.: 31.25%]\n",
            "epoch 34000: [D loss: 0.693854, acc.: 56.25%] [G loss: 0.719211, acc.: 46.88%]\n",
            "epoch 34200: [D loss: 0.715698, acc.: 50.00%] [G loss: 0.716524, acc.: 43.75%]\n",
            "epoch 34400: [D loss: 0.689936, acc.: 56.25%] [G loss: 0.737493, acc.: 31.25%]\n",
            "epoch 34600: [D loss: 0.697358, acc.: 50.00%] [G loss: 0.740230, acc.: 31.25%]\n",
            "epoch 34800: [D loss: 0.698957, acc.: 51.56%] [G loss: 0.756260, acc.: 40.62%]\n",
            "epoch 35000: [D loss: 0.689321, acc.: 57.81%] [G loss: 0.729640, acc.: 53.12%]\n",
            "epoch 35200: [D loss: 0.729912, acc.: 46.88%] [G loss: 0.790316, acc.: 12.50%]\n",
            "epoch 35400: [D loss: 0.691527, acc.: 54.69%] [G loss: 0.718389, acc.: 46.88%]\n",
            "epoch 35600: [D loss: 0.680650, acc.: 53.12%] [G loss: 0.733227, acc.: 25.00%]\n",
            "epoch 35800: [D loss: 0.687858, acc.: 53.12%] [G loss: 0.657168, acc.: 71.88%]\n",
            "epoch 36000: [D loss: 0.695439, acc.: 54.69%] [G loss: 0.705298, acc.: 53.12%]\n",
            "epoch 36200: [D loss: 0.688722, acc.: 59.38%] [G loss: 0.814709, acc.: 43.75%]\n",
            "epoch 36400: [D loss: 0.695739, acc.: 45.31%] [G loss: 0.717503, acc.: 43.75%]\n",
            "epoch 36600: [D loss: 0.697205, acc.: 57.81%] [G loss: 0.709713, acc.: 37.50%]\n",
            "epoch 36800: [D loss: 0.696286, acc.: 54.69%] [G loss: 0.663434, acc.: 71.88%]\n",
            "epoch 37000: [D loss: 0.687781, acc.: 51.56%] [G loss: 0.722798, acc.: 37.50%]\n",
            "epoch 37200: [D loss: 0.720763, acc.: 43.75%] [G loss: 0.749412, acc.: 40.62%]\n",
            "epoch 37400: [D loss: 0.724255, acc.: 46.88%] [G loss: 0.665283, acc.: 56.25%]\n",
            "epoch 37600: [D loss: 0.682059, acc.: 53.12%] [G loss: 0.634665, acc.: 68.75%]\n",
            "epoch 37800: [D loss: 0.699614, acc.: 48.44%] [G loss: 0.653970, acc.: 53.12%]\n",
            "epoch 38000: [D loss: 0.694269, acc.: 48.44%] [G loss: 0.735001, acc.: 46.88%]\n",
            "epoch 38200: [D loss: 0.706664, acc.: 46.88%] [G loss: 0.714576, acc.: 43.75%]\n",
            "epoch 38400: [D loss: 0.704637, acc.: 50.00%] [G loss: 0.703603, acc.: 46.88%]\n",
            "epoch 38600: [D loss: 0.658949, acc.: 67.19%] [G loss: 0.756114, acc.: 37.50%]\n",
            "epoch 38800: [D loss: 0.674902, acc.: 51.56%] [G loss: 0.689001, acc.: 50.00%]\n",
            "epoch 39000: [D loss: 0.791688, acc.: 39.06%] [G loss: 0.946450, acc.: 6.25%]\n",
            "epoch 39200: [D loss: 0.675373, acc.: 56.25%] [G loss: 0.648145, acc.: 65.62%]\n",
            "epoch 39400: [D loss: 0.683858, acc.: 57.81%] [G loss: 0.742000, acc.: 43.75%]\n",
            "epoch 39600: [D loss: 0.701268, acc.: 48.44%] [G loss: 0.708790, acc.: 56.25%]\n",
            "epoch 39800: [D loss: 0.699399, acc.: 53.12%] [G loss: 0.750789, acc.: 37.50%]\n",
            "epoch 40000: [D loss: 0.703699, acc.: 48.44%] [G loss: 0.682661, acc.: 65.62%]\n",
            "epoch 40200: [D loss: 0.694441, acc.: 51.56%] [G loss: 0.745881, acc.: 34.38%]\n",
            "epoch 40400: [D loss: 0.699946, acc.: 43.75%] [G loss: 0.719519, acc.: 43.75%]\n",
            "epoch 40600: [D loss: 0.666426, acc.: 60.94%] [G loss: 0.691379, acc.: 43.75%]\n",
            "epoch 40800: [D loss: 0.699863, acc.: 50.00%] [G loss: 0.696448, acc.: 46.88%]\n",
            "epoch 41000: [D loss: 0.710059, acc.: 45.31%] [G loss: 0.688121, acc.: 59.38%]\n",
            "epoch 41200: [D loss: 0.695452, acc.: 48.44%] [G loss: 0.692596, acc.: 50.00%]\n",
            "epoch 41400: [D loss: 0.698668, acc.: 46.88%] [G loss: 0.697228, acc.: 62.50%]\n",
            "epoch 41600: [D loss: 0.704243, acc.: 43.75%] [G loss: 0.698601, acc.: 37.50%]\n",
            "epoch 41800: [D loss: 0.699222, acc.: 56.25%] [G loss: 0.709006, acc.: 50.00%]\n",
            "epoch 42000: [D loss: 0.753216, acc.: 48.44%] [G loss: 0.832029, acc.: 21.88%]\n",
            "epoch 42200: [D loss: 0.712010, acc.: 45.31%] [G loss: 0.761266, acc.: 34.38%]\n",
            "epoch 42400: [D loss: 0.672343, acc.: 62.50%] [G loss: 0.771630, acc.: 34.38%]\n",
            "epoch 42600: [D loss: 0.718619, acc.: 50.00%] [G loss: 0.666239, acc.: 65.62%]\n",
            "epoch 42800: [D loss: 0.741755, acc.: 34.38%] [G loss: 0.731345, acc.: 46.88%]\n",
            "epoch 43000: [D loss: 0.700730, acc.: 54.69%] [G loss: 0.650048, acc.: 62.50%]\n",
            "epoch 43200: [D loss: 0.676166, acc.: 57.81%] [G loss: 0.727333, acc.: 43.75%]\n",
            "epoch 43400: [D loss: 0.712094, acc.: 45.31%] [G loss: 0.704145, acc.: 46.88%]\n",
            "epoch 43600: [D loss: 0.732932, acc.: 45.31%] [G loss: 0.788772, acc.: 31.25%]\n",
            "epoch 43800: [D loss: 0.712789, acc.: 50.00%] [G loss: 0.693096, acc.: 46.88%]\n",
            "epoch 44000: [D loss: 0.718239, acc.: 50.00%] [G loss: 0.570876, acc.: 87.50%]\n",
            "epoch 44200: [D loss: 0.689029, acc.: 50.00%] [G loss: 0.758756, acc.: 31.25%]\n",
            "epoch 44400: [D loss: 0.720396, acc.: 45.31%] [G loss: 0.741122, acc.: 53.12%]\n",
            "epoch 44600: [D loss: 0.716079, acc.: 48.44%] [G loss: 0.676324, acc.: 59.38%]\n",
            "epoch 44800: [D loss: 0.691825, acc.: 53.12%] [G loss: 1.112153, acc.: 3.12%]\n",
            "epoch 45000: [D loss: 0.685999, acc.: 54.69%] [G loss: 0.714223, acc.: 50.00%]\n",
            "epoch 45200: [D loss: 0.663773, acc.: 62.50%] [G loss: 0.736848, acc.: 34.38%]\n",
            "epoch 45400: [D loss: 0.702572, acc.: 46.88%] [G loss: 0.683342, acc.: 56.25%]\n",
            "epoch 45600: [D loss: 0.699213, acc.: 50.00%] [G loss: 0.716723, acc.: 50.00%]\n",
            "epoch 45800: [D loss: 0.678810, acc.: 53.12%] [G loss: 0.677619, acc.: 68.75%]\n",
            "epoch 46000: [D loss: 0.672848, acc.: 65.62%] [G loss: 0.694857, acc.: 56.25%]\n",
            "epoch 46200: [D loss: 0.712295, acc.: 53.12%] [G loss: 0.581496, acc.: 81.25%]\n",
            "epoch 46400: [D loss: 0.681917, acc.: 54.69%] [G loss: 0.718561, acc.: 43.75%]\n",
            "epoch 46600: [D loss: 0.697167, acc.: 50.00%] [G loss: 0.759811, acc.: 28.12%]\n",
            "epoch 46800: [D loss: 0.730044, acc.: 45.31%] [G loss: 0.826986, acc.: 21.88%]\n",
            "epoch 47000: [D loss: 0.673262, acc.: 60.94%] [G loss: 0.664596, acc.: 59.38%]\n",
            "epoch 47200: [D loss: 0.690354, acc.: 50.00%] [G loss: 0.789932, acc.: 15.62%]\n",
            "epoch 47400: [D loss: 0.698605, acc.: 56.25%] [G loss: 0.833407, acc.: 12.50%]\n",
            "epoch 47600: [D loss: 0.705371, acc.: 46.88%] [G loss: 0.640570, acc.: 75.00%]\n",
            "epoch 47800: [D loss: 0.701797, acc.: 50.00%] [G loss: 0.681215, acc.: 50.00%]\n",
            "epoch 48000: [D loss: 0.693995, acc.: 51.56%] [G loss: 0.731429, acc.: 34.38%]\n",
            "epoch 48200: [D loss: 0.653645, acc.: 62.50%] [G loss: 0.809777, acc.: 21.88%]\n",
            "epoch 48400: [D loss: 0.700353, acc.: 48.44%] [G loss: 0.707438, acc.: 31.25%]\n",
            "epoch 48600: [D loss: 0.683217, acc.: 53.12%] [G loss: 0.746840, acc.: 37.50%]\n",
            "epoch 48800: [D loss: 0.686853, acc.: 54.69%] [G loss: 0.666406, acc.: 53.12%]\n",
            "epoch 49000: [D loss: 0.702755, acc.: 51.56%] [G loss: 0.630696, acc.: 65.62%]\n",
            "epoch 49200: [D loss: 0.629690, acc.: 70.31%] [G loss: 0.856105, acc.: 25.00%]\n",
            "epoch 49400: [D loss: 0.670358, acc.: 65.62%] [G loss: 0.788726, acc.: 31.25%]\n",
            "epoch 49600: [D loss: 0.706849, acc.: 50.00%] [G loss: 0.612436, acc.: 78.12%]\n",
            "epoch 49800: [D loss: 0.736759, acc.: 46.88%] [G loss: 0.759406, acc.: 34.38%]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAHgCAYAAADt8bqrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf7khabnDAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y42JuxnO3Vaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}